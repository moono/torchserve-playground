inference_address=http://0.0.0.0:8080
management_address=http://0.0.0.0:8081
metrics_address=http://0.0.0.0:8082
number_of_netty_threads=32
job_queue_size=1000
# model_store=/tmp/models
model_store=/home/model-server/model-store
load_models=gpu_model=gpu_model.mar
default_workers_per_model=1
workflow_store=/home/model-server/wf-store